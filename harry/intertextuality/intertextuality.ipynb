{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Reuse and Intertextuality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. TEXT: Format the HP books and HP movie scripts to the TRACER format. For the movie scripts, this means taking out the names of the speakers. I can give you clear instructions on how to do TRACER formatting (all texts in one text file):\n",
    "```\n",
    "id of seven digits (book 1: 11, book 12) \\t sentence in tokenized version, lowercased tokens, splitted along whitespace \\t \"NULL\" \\t \"book 1, chapter 1\" (free field)\n",
    "1100001 quod sit officium sapientis .   NULL    Summa Contra Gentiles\n",
    "1100002 veritatem meditabitur guttur meum , et labia mea detestabuntur impium .     NULL    Summa Contra Gentiles\n",
    "1100003 prov. 8-7 .     NULL    Summa Contra Gentiles\n",
    "1100004 multitudinis usus , quem in rebus nominandis sequendum philosophus censet , communiter obtinuit ut sapientes dicantur qui res directe ordinant et eas bene gubernant .  NULL    Summa Contra Gentiles\n",
    "```\n",
    "\n",
    "2. SYNONYMS: For near-verbatim/paraphrase detection, you need an English list of synonyms or thesaurus. This can be extracted from Wordnet and also needs to be formatted as a bidirectional list in two columns. I can also give you details for this. Problem is: many HP neologisms won't be in a standard thesaurus. This gives us two options:\n",
    "(If we don't do this, we will only superexact matches.)\n",
    "    * exhaustive list of synonyms but only for words in movie scripts or books; also add british vs american list\n",
    "    * has to be \"directional\". E.g.\n",
    "\n",
    "```\n",
    "- love \\t care\n",
    "- care \\t love\n",
    "```\n",
    "3. LEMMAS: PoS-tag and lemmatise the corpus. Here I ask that you do it with StanfordCore NLP as the output is recognised by TRACER and no extra conversion is needed.\n",
    "```\n",
    "lowercased wordform \\t baseform/lemma from corenlp \\t postag \\n\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important to use same tokenizer for both data streams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep track of unique words occuring:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First subtitles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01-Harry_Potter_and_the_Sorcerer_s_Stone\n",
      "02-Harry_Potter_and_the_Chamber_of_Secrets\n",
      "03-Harry_Potter_and_the_Prisoner_of_Azkaban\n",
      "04-Harry_Potter_And_The_Goblet_Of_Fire\n",
      "05-Harry_Potter_and_the_Order_of_the_Phoenix\n",
      "06-Harry_Potter_And_The_Half_blood_Prince\n",
      "07a-Harry_Potter_and_Deathly_Hallows_Part_1\n",
      "07b-Harry_Potter_And_Deathly_Hallows_Part_2\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import pysrt\n",
    "\n",
    "with open('movies.txt', 'w') as new_file:\n",
    "    filenames = sorted(glob.glob('/Users/mike/GitRepos/potter/data/subtitles/*.srt'))\n",
    "    title_cnt = 10\n",
    "    \n",
    "    for filename in filenames:\n",
    "        title_cnt += 1\n",
    "        title = os.path.basename(filename).split('.')[0]\n",
    "        title = title.split('(')[0].strip().replace(' ', '_')\n",
    "        print(title)\n",
    "        \n",
    "        sub_cnt = 0\n",
    "        for sub in pysrt.open(filename):\n",
    "            sub_cnt += 1\n",
    "            \n",
    "            start_time = sub.end.to_time().strftime('%H:%M:%S')\n",
    "            end_time = sub.end.to_time().strftime('%H:%M:%S')\n",
    "            info = title + '-' + start_time + '-' + end_time\n",
    "            \n",
    "            text = ' '.join(sub.text_without_tags.split())\n",
    "            tokens = [t.lower() for t in word_tokenize(text)]\n",
    "            \n",
    "            vocab.update(tokens)\n",
    "            \n",
    "            c = str(sub_cnt)\n",
    "            while len(c) < 6:\n",
    "                c = '0' + c\n",
    "\n",
    "            new_file.write(str(title_cnt) + c + '\\t' + ' '.join(tokens) + '\\tFULL\\t' + info + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then novels (UK version, although movies might be closer in language and spelling to US):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "from collections import OrderedDict\n",
    "\n",
    "def load_potter(fn):\n",
    "    series = etree.parse(fn)\n",
    "    HP = OrderedDict()\n",
    "    for book in series.iterfind('.//book'):\n",
    "        book_title = book.attrib['title']\n",
    "        #print(book_title)\n",
    "        HP[book_title] = OrderedDict()\n",
    "        \n",
    "        for chapter in book.iterfind('.//chapter'):\n",
    "            chapter_title = chapter.attrib['title']\n",
    "            #print('   ', chapter_title)\n",
    "            HP[book_title][chapter_title] = []\n",
    "            \n",
    "            for paragraph in chapter.iterfind('.//p'):\n",
    "                text = ''.join([x for x in paragraph.itertext()])\n",
    "                HP[book_title][chapter_title].append(text)\n",
    "    return HP\n",
    "\n",
    "novels = load_potter('../preprocessing/simple_potter_uk.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harry Potter and the Philosopher's Stone\n",
      "Harry Potter and the Chamber of Secrets\n",
      "Harry Potter and the Prisoner of Azkaban\n",
      "Harry Potter and the Goblet of Fire\n",
      "Harry Potter and the Order of the Phoenix\n",
      "Harry Potter and the Half Blood Prince\n",
      "Harry Potter and the Deathly Hallows\n"
     ]
    }
   ],
   "source": [
    "with open('books.txt', 'w') as new_file:\n",
    "    book_cnt = 10\n",
    "    for book in novels:\n",
    "        print(book)\n",
    "        book_cnt += 1\n",
    "        for chapter in novels[book]:\n",
    "            sent_cnt = 0\n",
    "            for paragraph in novels[book][chapter]:\n",
    "                for sentence in sent_tokenize(paragraph):\n",
    "                    sent_cnt += 1\n",
    "                    tokens = word_tokenize(sentence.strip())\n",
    "                    tokens = [t.lower() for t in tokens]\n",
    "                    vocab.update(tokens)\n",
    "                    info = book.replace(' ', '_') + '-' + chapter.replace(' ', '_')\n",
    "                    c = str(sent_cnt)\n",
    "                    while len(c) < 6:\n",
    "                        c = '0' + c\n",
    "                    new_file.write(str(book_cnt) + c + '\\t' + ' '.join(tokens) + '\\tFULL\\t' + info + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract synonyms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many unique words did we collect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23467\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\n",
      "#\n",
      "&\n",
      "'\n",
      "''\n",
      "''an\n",
      "''come\n",
      "''get\n",
      "''glistening\n",
      "''magical\n",
      "''marvelous\n",
      "''me\n",
      "''miss\n",
      "''old\n",
      "''potentially\n",
      "''try\n",
      "'d\n",
      "'did\n",
      "'em\n",
      "'hey\n",
      "'ll\n",
      "'m\n",
      "'prolly\n",
      "'re\n",
      "'s\n",
      "'t\n",
      "'ve\n",
      "'you\n",
      "'your\n",
      "(\n",
      ")\n",
      "*\n",
      ",\n",
      "-\n",
      "--\n",
      "-a\n",
      "-absolutely\n",
      "-alastor\n",
      "-albus\n",
      "-all\n",
      "-amazing\n",
      "-and\n",
      "-any\n",
      "-are\n",
      "-attention\n",
      "-auror\n",
      "-avada\n",
      "-axxo-\n",
      "-barty\n",
      "-because\n",
      "-besides\n",
      "-better\n",
      "-bodied\n",
      "-bonsoir\n",
      "-bottoms\n",
      "-brilliant\n",
      "-but\n",
      "-ced\n",
      "-cedric\n",
      "-cho\n",
      "-come\n",
      "-congratulations\n",
      "-cooked\n",
      "-crime\n",
      "-crouch\n",
      "-curse\n",
      "-did\n",
      "-do\n",
      "-dress\n",
      "-dumb\n",
      "-everything\n",
      "-excellent\n",
      "-excuse\n",
      "-expelliarmus\n",
      "-feet\n",
      "-fine\n",
      "-fleur\n",
      "-follow\n",
      "-for\n",
      "-four\n",
      "-fourteen\n",
      "-get\n",
      "-ginny\n",
      "-go\n",
      "-good\n",
      "-great\n",
      "-hagrid\n",
      "-harry\n",
      "-have\n",
      "-he\n",
      "-hello\n",
      "-here\n",
      "-hermione\n",
      "-hey\n",
      "-hi\n",
      "-his\n",
      "-how\n",
      "-just\n",
      "-keep\n",
      "-kill\n",
      "-knew\n",
      "-krum\n",
      "-l\n",
      "-least\n",
      "-let\n",
      "-lf\n",
      "-look\n",
      "-ls\n",
      "-lt\n",
      "-moral\n",
      "-most\n",
      "-mr.\n",
      "-my\n",
      "-never\n",
      "-neville\n",
      "-next\n",
      "-no\n",
      "-nothing\n",
      "-now\n",
      "-oh\n",
      "-oi\n",
      "-one\n",
      "-or\n",
      "-pack\n",
      "-pathetic\n",
      "-perhaps\n",
      "-potter\n",
      "-professor\n",
      "-put\n",
      "-quiet\n",
      "-read\n",
      "-ready\n",
      "-really\n",
      "-right\n",
      "-ron\n",
      "-rosier\n",
      "-second\n",
      "-see\n",
      "-shall\n",
      "-she\n",
      "-shut\n",
      "-silence\n",
      "-simple\n",
      "-snape\n",
      "-someone\n",
      "-stupid\n",
      "-such\n",
      "-surely\n",
      "-take\n",
      "-teaching\n",
      "-technically\n",
      "-thank\n",
      "-thanks\n",
      "-that\n",
      "-the\n",
      "-there\n",
      "-they\n",
      "-this\n",
      "-three\n",
      "-to\n",
      "-today\n",
      "-together\n",
      "-total\n",
      "-two\n",
      "-we\n",
      "-weasley\n",
      "-well\n",
      "-what\n",
      "-when\n",
      "-where\n",
      "-which\n",
      "-who\n",
      "-why\n",
      "-wicked\n",
      "-yeah\n",
      "-years\n",
      "-yes\n",
      "-you\n",
      "-your\n",
      ".\n",
      "..\n",
      "...\n",
      ".a\n",
      ".about\n",
      ".after\n",
      ".again\n",
      ".and\n",
      ".are\n",
      ".as\n",
      ".at\n",
      ".back-shooting\n",
      ".begged\n",
      ".begin\n",
      ".besides\n",
      ".but\n",
      ".by\n",
      ".cast\n",
      ".cedric\n",
      ".could\n",
      ".council\n",
      ".dashing\n",
      ".disappointed\n",
      ".each\n",
      ".exceptionally\n",
      ".exhilarated\n",
      ".for\n",
      ".forcibly\n",
      ".gather\n",
      ".had\n",
      ".has\n",
      ".he\n",
      ".here\n",
      ".how\n",
      ".if\n",
      ".in\n",
      ".infinitely\n",
      ".into\n",
      ".is\n",
      ".it\n",
      ".junior\n",
      ".kind\n",
      ".knowing\n",
      ".l\n",
      ".let\n",
      ".longing\n",
      ".lucius\n",
      ".me\n",
      ".ministry\n",
      ".miss\n",
      ".mr\n",
      ".my\n",
      ".need\n",
      ".no\n",
      ".not\n",
      ".now\n",
      ".obliged\n",
      ".of\n",
      ".on\n",
      ".our\n",
      ".perhaps\n",
      ".pluck\n",
      ".second\n",
      ".seems\n",
      ".shall\n",
      ".she\n",
      ".should\n",
      ".silenced\n",
      ".since\n",
      ".some\n",
      ".something\n",
      ".sorry\n",
      ".stirring\n",
      ".that\n",
      ".the\n",
      ".then\n",
      ".there\n",
      ".these\n",
      ".they\n",
      ".this\n",
      ".though\n",
      ".three\n",
      ".to\n",
      ".torture\n",
      ".turned\n",
      ".under\n",
      ".unwillingly\n",
      ".we\n",
      ".what\n",
      ".when\n",
      ".who\n",
      ".willingly\n",
      ".without\n",
      ".you\n",
      "0\n",
      "0-1\n",
      "1\n",
      "10\n",
      "10-year-old\n",
      "100\n",
      "10:58\n",
      "11\n",
      "11:00\n",
      "12\n",
      "12.30\n",
      "12.75\n",
      "125\n",
      "1289\n",
      "1296\n",
      "12th\n",
      "13\n",
      "13-year-old\n",
      "14\n",
      "1473\n",
      "1492\n",
      "15\n",
      "150\n",
      "16\n",
      "16-year-old\n",
      "1612\n",
      "1612–1697\n",
      "1637\n",
      "1689\n",
      "17\n",
      "1709\n",
      "1722\n",
      "1722–1741\n",
      "1741–1768\n",
      "1749\n",
      "1792\n",
      "1875\n",
      "1890\n",
      "19\n",
      "1945\n",
      "1960\n",
      "1981\n",
      "1:00\n",
      "2\n",
      "2000\n",
      "2001\n",
      "21\n",
      "23\n",
      "27\n",
      "27th\n",
      "3\n",
      "3/4\n",
      "30\n",
      "30th\n",
      "31\n",
      "312\n",
      "31st\n",
      "352\n",
      "36\n",
      "37\n",
      "382\n",
      "394\n",
      "4\n",
      "4.30\n",
      "422nd\n",
      "426\n",
      "472\n",
      "49\n",
      "5\n",
      "50\n",
      "500\n",
      "6\n",
      "6.1\n",
      "60\n",
      "665th\n",
      "687\n",
      "6:00\n",
      "6:23\n",
      "7\n",
      "7.\n",
      "713\n",
      "7:30\n",
      "800\n",
      "9\n",
      "90\n",
      "93/4\n",
      ":\n",
      ";\n",
      "?\n",
      "@\n",
      "[\n",
      "]\n",
      "``\n",
      "a\n",
      "a-creeping\n",
      "a.\n",
      "a.p.w.b.d\n",
      "aaaaaaaaaaaaaarrrrrrrrrrrrggghhhhh\n",
      "aaaaaaaaaaargh\n",
      "aaaaaaaaargh\n",
      "aaaaaaaargh\n",
      "aaaaaaaarrrrrgh\n",
      "aaaaaaand\n",
      "aaaaaaarrrgh\n",
      "aaaaaah\n",
      "aaaaaand\n",
      "aaaaah\n",
      "aaaaahed\n",
      "aaaaargh\n",
      "aaaaarrrgh\n",
      "aaaah\n",
      "aaaargh\n",
      "aaah\n",
      "aaargh\n",
      "aah\n",
      "aargh\n",
      "ab\n",
      "aback\n",
      "abandon\n",
      "abandoned\n",
      "abandoning\n",
      "abandonment\n",
      "abashed\n",
      "abate\n",
      "abated\n",
      "abbott\n",
      "abercrombie\n",
      "aberdeen\n",
      "aberforth\n",
      "abergavenny\n",
      "abetted\n",
      "abide\n",
      "abided\n",
      "abilities\n",
      "abilities.\n",
      "ability\n",
      "abject\n",
      "ablaze\n",
      "able\n",
      "able-bodied\n",
      "abnormal\n",
      "abnormality\n",
      "abnormally\n",
      "aboard\n",
      "abomination\n",
      "abou\n",
      "about\n",
      "above\n",
      "abrasions\n",
      "abraxan\n",
      "abraxas\n",
      "abroad\n",
      "abrupt\n",
      "abruptly\n",
      "abruptness\n",
      "absence\n",
      "absences\n",
      "absent\n",
      "absent-mindedly\n",
      "absently\n",
      "absolute\n",
      "absolutely\n",
      "absorb\n",
      "absorbed\n",
      "absorbing\n",
      "abstained\n",
      "abstinence\n",
      "abstract\n",
      "absurd\n",
      "absurdity\n",
      "absurdly\n",
      "abuse\n",
      "abused\n",
      "abusing\n",
      "abysmal\n",
      "abysmally\n",
      "abyssinian\n",
      "academic\n",
      "academical\n",
      "academy\n",
      "accelerated\n",
      "accelerating\n",
      "acceleration\n",
      "accelerator\n",
      "accent\n",
      "accents\n",
      "accept\n",
      "acceptable\n",
      "acceptance\n",
      "accepted\n",
      "accepting\n",
      "accepts\n",
      "access\n",
      "accessible\n",
      "accessorised\n",
      "accident\n",
      "accident-prone\n",
      "accidental\n",
      "accidentally\n",
      "accidentally-on-purpose\n",
      "accidents\n",
      "accio\n",
      "acclaimed\n",
      "acclimatise\n",
      "accommodate\n",
      "accommodated\n",
      "accommodating\n",
      "accompanied\n",
      "accompaniment\n",
      "accompany\n",
      "accompanying\n",
      "accomplice\n",
      "accomplices\n",
      "accomplish\n",
      "accomplished\n",
      "accomplishing\n",
      "accord\n",
      "accordance\n",
      "accorded\n",
      "according\n",
      "accordingly\n",
      "accosted\n",
      "account\n",
      "accountability\n",
      "accountant\n",
      "accounts\n",
      "accumulated\n",
      "accuracy\n",
      "accurate\n",
      "accurately\n",
      "accursed\n",
      "accusation\n",
      "accusations\n",
      "accusatory\n",
      "accuse\n",
      "accused\n",
      "accusers\n",
      "accuses\n",
      "accusing\n",
      "accusingly\n",
      "accustomed\n",
      "ache\n",
      "ached\n",
      "aches\n",
      "achievable\n",
      "achieve\n",
      "achieved\n",
      "achievement\n",
      "achievements\n",
      "achieving\n",
      "aching\n",
      "achingly\n",
      "acid\n",
      "acid-green\n",
      "acidly\n",
      "ackerley\n",
      "acknowledge\n",
      "acknowledged\n",
      "acknowledgement\n",
      "acknowledges\n",
      "acknowledging\n",
      "acne\n",
      "aconite\n",
      "acorn\n",
      "acquaintance\n",
      "acquire\n",
      "acquired\n",
      "acquisition\n",
      "acquitted\n",
      "acres\n",
      "acrid\n",
      "acromantula\n",
      "across\n",
      "act\n",
      "acted\n",
      "acting\n",
      "action\n",
      "action-packed\n",
      "actions\n",
      "actions.\n",
      "activated\n",
      "active\n",
      "actively\n",
      "activities\n",
      "activity\n",
      "actor\n",
      "actress\n",
      "acts\n",
      "actual\n",
      "actually\n",
      "acute\n",
      "ad\n",
      "adam\n",
      "adamant\n",
      "adapted\n",
      "add\n",
      "addacked\n",
      "added\n",
      "adder\n",
      "addic7ed.com\n",
      "adding\n",
      "addition\n",
      "additional\n",
      "additions\n",
      "addled\n",
      "address\n",
      "addressed\n",
      "addressee\n",
      "addressing\n",
      "adds\n",
      "adept\n",
      "adequate\n",
      "adjacent\n",
      "adjoining\n",
      "adjust\n",
      "adjusted\n",
      "adjusting\n",
      "adjustment\n",
      "administer\n",
      "administered\n",
      "administration\n",
      "admirable\n",
      "admirably\n",
      "admiration\n",
      "admire\n",
      "admired\n",
      "admirer\n",
      "admirers\n",
      "admiring\n",
      "admiringly\n",
      "admit\n",
      "admits\n",
      "admitted\n",
      "admittedly\n",
      "admitting\n",
      "admonitions\n",
      "admonitory\n",
      "ado\n",
      "adolescent\n",
      "adopt\n",
      "adopted\n",
      "adopting\n",
      "adoration\n",
      "adored\n",
      "adoringly\n",
      "adorned\n",
      "adrenaline\n",
      "adrian\n",
      "adult\n",
      "adult-sized\n",
      "adults\n",
      "advance\n",
      "advanced\n",
      "advances\n",
      "advancing\n",
      "advantage\n",
      "adventure\n",
      "adventures\n",
      "adversary\n",
      "advertise\n",
      "advertisement\n",
      "advertisements\n",
      "adverts\n",
      "advice\n",
      "advisability\n",
      "advisable\n",
      "advise\n",
      "advised\n",
      "advises\n",
      "advising\n",
      "advisor\n",
      "advisory\n",
      "aerial\n",
      "aerials\n",
      "aeroplane\n",
      "aeroplanes\n",
      "afar\n",
      "affably\n",
      "affair\n",
      "affairs\n",
      "affect\n",
      "affected\n",
      "affecting\n",
      "affection\n",
      "affectionate\n",
      "affectionately\n",
      "affects\n",
      "affinity\n",
      "affixed\n",
      "affliction\n",
      "afflictions\n",
      "afford\n",
      "afforded\n",
      "affording\n",
      "affronted\n",
      "aff–\n",
      "aflame\n",
      "afoul\n",
      "afraid\n",
      "afresh\n",
      "africa\n",
      "african\n",
      "after\n",
      "after-dinner\n",
      "after-effects\n",
      "after-lunch\n",
      "after-match\n",
      "aftermath\n",
      "afternoon\n",
      "afternoons\n",
      "afters\n",
      "aftershave\n",
      "afterthought\n",
      "afterwards\n",
      "again\n",
      "agains\n",
      "against\n",
      "agapanthuses\n",
      "agape\n",
      "agatha\n",
      "age\n",
      "age-appropriate\n",
      "age-blackened\n",
      "age-spotted\n",
      "aged\n",
      "ageing\n",
      "agent\n",
      "ages\n",
      "aggiden\n",
      "aggravated\n",
      "aggravating\n",
      "aggression\n",
      "aggressive\n",
      "aggressively\n",
      "aggrieved\n",
      "aghast\n",
      "agile\n",
      "agility\n",
      "aging\n",
      "agis\n",
      "agitated\n",
      "agitatedly\n",
      "agitating\n",
      "agitation\n",
      "agleam\n",
      "aglow\n",
      "agnes\n",
      "ago\n",
      "agog\n",
      "agonised\n",
      "agonising\n",
      "agony\n",
      "agree\n",
      "agreeable\n",
      "agreed\n",
      "agreeing\n",
      "agreement\n",
      "agrees\n",
      "agriculture\n",
      "agrid\n",
      "agrippa\n",
      "aguamenti\n",
      "ah\n",
      "aha\n",
      "ahead\n",
      "ahem\n",
      "ahoy\n",
      "ai\n",
      "aid\n",
      "aidan\n",
      "aided\n",
      "aiding\n",
      "aids\n",
      "ailing\n",
      "ailments\n",
      "aim\n",
      "aimed\n",
      "aiming\n",
      "aimlessly\n",
      "aims\n",
      "ain\n",
      "air\n",
      "air-rifle\n",
      "airborne\n",
      "airier\n",
      "airily\n",
      "airiness\n",
      "airing\n",
      "airless\n",
      "airnet\n",
      "airports\n",
      "airwaves\n",
      "airway\n",
      "airy\n",
      "airy-fairy\n",
      "aisle\n",
      "aisles\n",
      "ajar\n",
      "al\n",
      "alarm\n",
      "alarmed\n",
      "alarming\n",
      "alarmingly\n",
      "alarms\n",
      "alarte\n",
      "alas\n",
      "alastor\n",
      "albania\n",
      "albanian\n",
      "albeit\n",
      "alberic\n",
      "albert\n",
      "albino\n",
      "album\n",
      "albus\n",
      "alchemical\n",
      "alchemist\n",
      "alchemy\n",
      "alderton\n",
      "alecto\n",
      "alert\n",
      "alerted\n",
      "alerting\n",
      "alertly\n",
      "alf\n",
      "alf-giant\n",
      "alfred\n",
      "algae\n",
      "algie\n",
      "ali\n",
      "alibis\n",
      "alice\n",
      "alicia\n",
      "alien\n",
      "alight\n",
      "alighted\n",
      "alike\n",
      "alive\n",
      "all\n",
      "all-clear\n",
      "all-consuming\n",
      "all-england\n",
      "all-knowing\n",
      "all-magic\n",
      "all-night\n",
      "all-powerful\n",
      "all-purpose\n",
      "all-time\n",
      "all-witch\n",
      "all-wizard\n",
      "all.\n",
      "alleged\n",
      "allegiance\n",
      "alleging\n",
      "allergic\n",
      "alleviate\n",
      "alley\n",
      "alleys\n",
      "alleyway\n",
      "alleyways\n",
      "allies\n",
      "allotted\n",
      "allow\n",
      "allowances\n",
      "allowed\n",
      "allowing\n",
      "allows\n",
      "allright\n",
      "alls\n",
      "allusion\n",
      "allusions\n",
      "ally\n",
      "almighty\n",
      "almond-shaped\n",
      "almost\n",
      "almost-deserted\n",
      "almost-full\n",
      "aloft\n",
      "alohomora\n",
      "alohomora.\n",
      "alone\n",
      "along\n",
      "alongside\n",
      "aloofly\n",
      "aloud\n",
      "alphabetical\n",
      "alphard\n",
      "already\n",
      "alright\n",
      "also\n",
      "alter\n",
      "alterations\n",
      "altered\n",
      "alternate\n",
      "alternately\n",
      "alternative\n",
      "although\n",
      "altogether\n",
      "alvays\n",
      "always\n",
      "alwyas\n",
      "am\n",
      "am.\n",
      "amanda\n",
      "amassed\n",
      "amaze\n",
      "amazed\n",
      "amazement\n",
      "amazes\n",
      "amazing\n",
      "amazingly\n",
      "amber\n",
      "ambition\n",
      "ambitions\n",
      "ambitious\n",
      "amble\n",
      "ambled\n",
      "ambling\n",
      "ambrosius\n",
      "ambush\n",
      "ambushed\n",
      "amelia\n",
      "amended\n",
      "amendment\n",
      "amends\n",
      "american\n",
      "americans\n",
      "amethyst-coloured\n",
      "amicably\n",
      "amid\n",
      "amidst\n",
      "amigo\n",
      "amiss\n",
      "amok\n",
      "among\n",
      "amongst\n",
      "amortentia\n",
      "amos\n",
      "amount\n",
      "amounts\n",
      "amphitheatre\n",
      "ample\n",
      "amplified\n",
      "ampoule\n",
      "amulet\n",
      "amulets\n",
      "amuse\n",
      "amused\n",
      "amusement\n",
      "amusin\n",
      "amusing\n",
      "amy\n",
      "amycus\n",
      "an\n",
      "analysis\n",
      "anapneo\n",
      "ancestor\n",
      "ancestors\n",
      "ancestry\n",
      "anchor\n",
      "anchors\n",
      "ancient\n",
      "ancient-looking\n",
      "and\n",
      "andling\n",
      "andorran\n",
      "andrew\n",
      "andromeda\n",
      "anecdote\n",
      "anecdotes\n",
      "anew\n",
      "ang\n",
      "angel\n",
      "angelina\n",
      "anger\n",
      "angered\n",
      "angle\n",
      "angled\n",
      "angles\n",
      "anglesey\n",
      "anglia\n",
      "angling\n",
      "anglo-saxon\n",
      "angrier\n",
      "angrily\n",
      "angry\n",
      "angry-looking\n",
      "anguish\n",
      "anguished\n",
      "angular\n",
      "angus\n",
      "animagi\n",
      "animagus\n",
      "animal\n",
      "animals\n",
      "animated\n",
      "animatedly\n",
      "animosity\n",
      "ankle\n",
      "ankle-deep\n",
      "ankles\n",
      "annotations\n",
      "announce\n",
      "announced\n",
      "announcement\n",
      "announces\n",
      "announcing\n",
      "annoy\n",
      "annoyance\n",
      "annoyed\n",
      "annoying\n",
      "annoyingly\n",
      "annoys\n",
      "annual\n",
      "annually\n",
      "anomaly\n",
      "anonymously\n",
      "another\n",
      "anothers\n",
      "answer\n",
      "answerd\n",
      "answered\n",
      "answering\n",
      "answers\n",
      "ant\n",
      "antagonise\n",
      "ante-chamber\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "with open('synonyms.txt', 'w') as f:\n",
    "    for word in sorted(vocab)[:1000]:\n",
    "        for synset in wn.synsets(word):\n",
    "            for synonym in synset.lemma_names():\n",
    "                if synonym.lower() != word:\n",
    "                    f.write('\\t'.join((word, synonym)) + '\\n')\n",
    "                    f.write('\\t'.join((synonym, word)) + '\\n')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provide lemmas and tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harry Potter and the Philosopher's Stone\n",
      "Harry Potter and the Chamber of Secrets\n",
      "Harry Potter and the Prisoner of Azkaban\n",
      "Harry Potter and the Goblet of Fire\n",
      "Harry Potter and the Order of the Phoenix\n",
      "Harry Potter and the Half Blood Prince\n",
      "Harry Potter and the Deathly Hallows\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "items = set()\n",
    "\n",
    "for book in novels:\n",
    "    print(book)\n",
    "    for chapter in novels[book]:\n",
    "        for paragraph in novels[book][chapter]:\n",
    "            for sentence in sent_tokenize(paragraph):\n",
    "                for token in nlp(sentence):\n",
    "                    form = token.text.lower()\n",
    "                    lemma = token.lemma_.lower()\n",
    "                    pos = token.tag_\n",
    "                items.add(tuple([form, lemma, pos]))\n",
    "\n",
    "with open('lemma_pos.txt', 'w') as new_file:\n",
    "    for item in items:\n",
    "        new_file.write('\\t'.join(item) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:clean36]",
   "language": "python",
   "name": "conda-env-clean36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
